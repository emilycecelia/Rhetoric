{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos, Stem, and Ngrams: Oh My!\n",
    "<img src=\"images/fdr.jpg\" height=\"200\" width=\"200\" align=\"left\">\n",
    "<center>\n",
    "<h3>In This Worksheet</h3> We will parse a new text using the methods described up to this point and introduce some new ways to characterize words and sentences in texts.\n",
    "<h3>The Data</h3> <strong>Pearl Harbor Address to the Nation</strong><br><i>President Franklin Delano Roosevelt, December 8th, 1941</i><br>\n",
    "This is FDR's call to war to the American people after Pearl Harbor.<br>\n",
    "https://youtu.be/3VqQAf74fsE\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp = 'speeches/FDR-PearlHarbor.txt'\n",
    "speech = open(fp).read().lower()\n",
    "\n",
    "rows = []\n",
    "sent_id = 0\n",
    "for sentence in sent_tokenize(speech):\n",
    "    for word in word_tokenize(sentence):\n",
    "        info = {'token':word, 'sent_id':sent_id}\n",
    "        rows.append(info)\n",
    "    sent_id += 1\n",
    "    \n",
    "parsed_speech = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mr.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>vice</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>president</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>mr.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id      token is_stop is_punct\n",
       "0        0        mr.   False    False\n",
       "1        0       vice   False    False\n",
       "2        0  president   False    False\n",
       "3        0          ,   False     True\n",
       "4        0        mr.   False    False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_stopword(token):\n",
    "    stops = stopwords.words('english').copy()\n",
    "    return token in stops\n",
    "\n",
    "def is_punctuation(token):\n",
    "    return token in string.punctuation\n",
    "\n",
    "parsed_speech['is_stop'] = parsed_speech.token.apply(is_stopword)\n",
    "parsed_speech['is_punct'] = parsed_speech['token'].apply(is_punctuation)\n",
    "\n",
    "parsed_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 'NN'), ('saw', 'VBD'), ('a', 'DT'), ('dog', 'NN'), ('running', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "tokenized_sentence = word_tokenize('I saw a dog running.'.lower())\n",
    "print(pos_tag(tokenized_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tag|Description|Example|\n",
    "|---|---|---|\n",
    "|CC|conjunction, coordinating|and, or, but|\n",
    "|CD|cardinal number|five, three, 13%|\n",
    "|DT|determiner|the, a, these |\n",
    "|EX|existential there|there were six boys |\n",
    "|FW|foreign word|mais |\n",
    "|IN|conjunction, subordinating or preposition|of, on, before, unless |\n",
    "|JJ|adjective|nice, easy|\n",
    "|JJR|adjective, comparative|nicer, easier|\n",
    "|JJS|adjective, superlative|nicest, easiest |\n",
    "|LS|list item marker| |\n",
    "|MD|verb, modal auxillary|may, should |\n",
    "|NN|noun, singular or mass|tiger, chair, laughter |\n",
    "|NNS|noun, plural|tigers, chairs, insects |\n",
    "|NNP|noun, proper singular|Germany, God, Alice |\n",
    "|NNPS|noun, proper plural|we met two Christmases ago |\n",
    "|PDT|predeterminer|both his children |\n",
    "|POS|possessive ending|'s|\n",
    "|PRP|pronoun, personal|me, you, it |\n",
    "|PRP\\$|pronoun, possessive|my, your, our |\n",
    "|RB|adverb|extremely, loudly, hard  |\n",
    "|RBR|adverb, comparative|better |\n",
    "|RBS|adverb, superlative|best |\n",
    "|RP|adverb, particle|about, off, up |\n",
    "|SYM|symbol|None|\n",
    "|TO|infinitival to|what to do? |\n",
    "|UH|interjection|oh, oops, gosh |\n",
    "|VB|verb, base form|think |\n",
    "|VBZ|verb, 3rd person singular present|she thinks |\n",
    "|VBP|verb, non-3rd person singular present|I think |\n",
    "|VBD|verb, past tense|they thought |\n",
    "|VBN|verb, past participle|a sunken ship |\n",
    "|VBG|verb, gerund or present participle|thinking is fun |\n",
    "|WDT|wh-determiner|which, whatever, whichever |\n",
    "|WP|wh-pronoun, personal|what, who, whom |\n",
    "|WP\\$|wh-pronoun, possessive|whose, whosever |\n",
    "|WRB|wh-adverb|where, when |\n",
    "|.|punctuation mark, sentence closer|.;?* |\n",
    "|,|punctuation mark, comma|, |\n",
    "|:|punctuation mark, colon|: |\n",
    "|(|contextual separator, left paren|( |\n",
    "|)|contextual separator, right paren|) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pos(word):\n",
    "    return pos_tag([word])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#much faster when given as list\n",
    "pos_tags = pos_tag(parsed_speech.token.tolist())\n",
    "just_tags = [x[1] for x in pos_tags]\n",
    "parsed_speech['pos'] = pd.Series( just_tags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mr.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>vice</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>president</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>mr.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id      token is_stop is_punct pos\n",
       "0        0        mr.   False    False  JJ\n",
       "1        0       vice   False    False  NN\n",
       "2        0  president   False    False  NN\n",
       "3        0          ,   False     True   ,\n",
       "4        0        mr.   False    False  NN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN      111\n",
       "IN       71\n",
       "JJ       62\n",
       "DT       60\n",
       "NNS      36\n",
       ",        30\n",
       ".        26\n",
       "CC       24\n",
       "RB       22\n",
       "VB       20\n",
       "PRP      15\n",
       "PRP$     14\n",
       "VBN      14\n",
       "VBD      14\n",
       "VBP      13\n",
       "MD       11\n",
       "TO       11\n",
       "VBZ       6\n",
       "CD        5\n",
       ":         4\n",
       "VBG       3\n",
       "WDT       3\n",
       "WRB       2\n",
       "EX        1\n",
       "Name: pos, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_speech.pos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forces       6\n",
       "states       6\n",
       "japan        5\n",
       "people       5\n",
       "attack       5\n",
       "yesterday    4\n",
       "night        4\n",
       "i            4\n",
       "island       3\n",
       "peace        3\n",
       "Name: token, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_pos = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "parsed_speech[parsed_speech.pos.isin(noun_pos)].token.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "parsed_speech['stem'] = parsed_speech.token.apply(stemmer.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>pos</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mr.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>JJ</td>\n",
       "      <td>mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>vice</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>vice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>president</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>presid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>mr.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id      token is_stop is_punct pos    stem\n",
       "0        0        mr.   False    False  JJ     mr.\n",
       "1        0       vice   False    False  NN    vice\n",
       "2        0  president   False    False  NN  presid\n",
       "3        0          ,   False     True   ,       ,\n",
       "4        0        mr.   False    False  NN     mr."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_stops = parsed_speech[ (parsed_speech['is_stop'] == False) \n",
    "                         & (parsed_speech.is_punct == False) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "japanese     10\n",
       "american      6\n",
       "attacked      6\n",
       "forces        6\n",
       "united        6\n",
       "states        6\n",
       "people        5\n",
       "japan         5\n",
       "attack        5\n",
       "yesterday     4\n",
       "Name: token, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " no_stops.token.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attack      11\n",
       "japanes     10\n",
       "state        9\n",
       "unit         6\n",
       "forc         6\n",
       "american     6\n",
       "japan        5\n",
       "island       5\n",
       "peopl        5\n",
       "last         4\n",
       "Name: stem, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stops.stem.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CONVERT EVERYTHING TO SENTENCE thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mr.', 'vice'), ('vice', 'president'), ('president', ','), (',', 'mr.'), ('mr.', 'speaker'), ('speaker', ','), (',', 'members'), ('members', 'of'), ('of', 'the'), ('the', 'senate'), ('senate', ','), (',', 'and'), ('and', 'of'), ('of', 'the'), ('the', 'house'), ('house', 'of'), ('of', 'representatives'), ('representatives', ':'), (':', 'yesterday'), ('yesterday', ','), (',', 'december'), ('december', '7th'), ('7th', ','), (',', '1941'), ('1941', '--'), ('--', 'a'), ('a', 'date'), ('date', 'which'), ('which', 'will'), ('will', 'live'), ('live', 'in'), ('in', 'infamy'), ('infamy', '--'), ('--', 'the'), ('the', 'united'), ('united', 'states'), ('states', 'of'), ('of', 'america'), ('america', 'was'), ('was', 'suddenly'), ('suddenly', 'and'), ('and', 'deliberately'), ('deliberately', 'attacked'), ('attacked', 'by'), ('by', 'naval'), ('naval', 'and'), ('and', 'air'), ('air', 'forces'), ('forces', 'of'), ('of', 'the'), ('the', 'empire'), ('empire', 'of'), ('of', 'japan'), ('japan', '.')]\n"
     ]
    }
   ],
   "source": [
    "#ngrams on sentences\n",
    "from nltk import ngrams\n",
    "first_tokens = parsed_speech[parsed_speech.sent_id==0].token.tolist()\n",
    "bigrams = ngrams(first_tokens, 2)\n",
    "print(list(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mr.', 'vice', 'president'), ('vice', 'president', ','), ('president', ',', 'mr.'), (',', 'mr.', 'speaker'), ('mr.', 'speaker', ','), ('speaker', ',', 'members'), (',', 'members', 'of'), ('members', 'of', 'the'), ('of', 'the', 'senate'), ('the', 'senate', ','), ('senate', ',', 'and'), (',', 'and', 'of'), ('and', 'of', 'the'), ('of', 'the', 'house'), ('the', 'house', 'of'), ('house', 'of', 'representatives'), ('of', 'representatives', ':'), ('representatives', ':', 'yesterday'), (':', 'yesterday', ','), ('yesterday', ',', 'december'), (',', 'december', '7th'), ('december', '7th', ','), ('7th', ',', '1941'), (',', '1941', '--'), ('1941', '--', 'a'), ('--', 'a', 'date'), ('a', 'date', 'which'), ('date', 'which', 'will'), ('which', 'will', 'live'), ('will', 'live', 'in'), ('live', 'in', 'infamy'), ('in', 'infamy', '--'), ('infamy', '--', 'the'), ('--', 'the', 'united'), ('the', 'united', 'states'), ('united', 'states', 'of'), ('states', 'of', 'america'), ('of', 'america', 'was'), ('america', 'was', 'suddenly'), ('was', 'suddenly', 'and'), ('suddenly', 'and', 'deliberately'), ('and', 'deliberately', 'attacked'), ('deliberately', 'attacked', 'by'), ('attacked', 'by', 'naval'), ('by', 'naval', 'and'), ('naval', 'and', 'air'), ('and', 'air', 'forces'), ('air', 'forces', 'of'), ('forces', 'of', 'the'), ('of', 'the', 'empire'), ('the', 'empire', 'of'), ('empire', 'of', 'japan'), ('of', 'japan', '.')]\n"
     ]
    }
   ],
   "source": [
    "trigrams = ngrams(first_tokens, 3)\n",
    "print(list(trigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
