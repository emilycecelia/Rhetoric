{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Exercise 1\n",
    "This exercise will be using another speech by Churchill called 'We Will Fight On the Beaches'.  Listen to a bit here: https://www.youtube.com/watch?v=MkTw3_PmKtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the filepath of the speech.  Open the speech, read it, convert to lowercase, and store it in the variable ```speech```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp = 'speeches/Churchill-Beaches.txt'\n",
    "speech = open(fp).read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty list called ```rows``` and an integer set to 0 called ```sent_id```.  Then for each sentence in ```speech```, tokenize the sentence and for each token in the sentence, create a dictionary with keys and values for 'token' and 'sent_id'.  Then append each dictionary to ```rows```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "sent_id = 0\n",
    "\n",
    "for sent in sent_tokenize(speech):\n",
    "    sent_id += 1\n",
    "    for token in word_tokenize(sent):\n",
    "        d = {'sent_id':sent_id, 'token':token}\n",
    "        rows.append(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the ```rows``` list to create a pandas DataFrame called ```parsed_speech```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed_speech = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two new columns in ```parsed_speech```, 'is_stop' and 'is_punct', that each identify whether or not a token is a stopword or punctuation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_stopword(token):\n",
    "    stops = stopwords.words('english').copy()\n",
    "    return token in stops\n",
    "\n",
    "def is_punctuation(token):\n",
    "    return token in string.punctuation\n",
    "\n",
    "parsed_speech['is_stop'] = parsed_speech.token.apply(is_stopword)\n",
    "parsed_speech['is_punct'] = parsed_speech.token.apply(is_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Answer the following questions about the speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the ten least common words in the speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nazi          1\n",
       "fall          1\n",
       "armed         1\n",
       "try           1\n",
       "home          1\n",
       "any           1\n",
       "forth         1\n",
       "god’s         1\n",
       "famous        1\n",
       "subjugated    1\n",
       "Name: token, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_speech.token.value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the twenty most common words in the speech that are not stop words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",             35\n",
       "shall         12\n",
       ".              7\n",
       "fight          7\n",
       "island         3\n",
       "defend         3\n",
       "even           2\n",
       "seas           2\n",
       "confidence     2\n",
       "old            2\n",
       "growing        2\n",
       "large          2\n",
       "may            2\n",
       "strength       2\n",
       "good           2\n",
       "british        2\n",
       "empire         2\n",
       "made           2\n",
       "necessary      2\n",
       "gestapo        1\n",
       "Name: token, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_speech[parsed_speech.is_stop == False].token.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the number of tokens in the sentence with the largest number of tokens in the speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    163\n",
       "Name: sent_id, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_speech.sent_id.value_counts().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Creation\n",
    "Create a function called ```parse_speech_to_tokens``` that takes a filepath as input and returns a DataFrame with four columns: sent_id, token, is_punct, and is_stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_speech_to_tokens(fp):\n",
    "    speech = open(fp).read().lower()\n",
    "    rows = []\n",
    "    sent_id = 0\n",
    "\n",
    "    for sent in sent_tokenize(speech):\n",
    "        sent_id += 1\n",
    "        for token in word_tokenize(sent):\n",
    "            d = {'sent_id':sent_id, 'token':token, 'is_stop': is_stopword(token), 'is_punct': is_punctuation(token)}\n",
    "            rows.append(d)\n",
    "            \n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function on a new speech, FDR's Pearl Harbor speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_punct</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_punct is_stop  sent_id      token\n",
       "0    False   False        1        mr.\n",
       "1    False   False        1       vice\n",
       "2    False   False        1  president\n",
       "3     True   False        1          ,\n",
       "4    False   False        1        mr."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdr_fp = 'speeches/FDR-PearlHarbor.txt'\n",
    "fdr_parsed_speech = parse_speech(fdr_fp)\n",
    "fdr_parsed_speech.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we can save our work, save the DataFrame to a file as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdr_parsed_speech.to_csv('data/FDR-PearlHarbor_parsed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructure for Sentences\n",
    "This section will be even more guided and provide better skeletons.\n",
    "Objective: Make a dataframe where each row is a sentence in the text.  There are two approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1\n",
    "Starting with the filepath, read the file, ```sent_tokenize``` its contents, and as you iterate, create a dictionary entry for each sentence. Each dictionary should have the follow key/value pairs:\n",
    "* 'sentence': the sentence as a string\n",
    "* 'tokens': the sentence as a list of tokens\n",
    "\n",
    "Append each dictionary to the empty list ```sentences```.  Then convert the list to a DataFrame and store it in the variable ```sentence_df_1```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have, myself, full confidence that if all do...</td>\n",
       "      <td>[i, have, ,, myself, ,, full, confidence, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at any rate, that is what we are going to try ...</td>\n",
       "      <td>[at, any, rate, ,, that, is, what, we, are, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is the resolve of his majesty’s governmen...</td>\n",
       "      <td>[that, is, the, resolve, of, his, majesty’s, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that is the will of parliament and the nation.</td>\n",
       "      <td>[that, is, the, will, of, parliament, and, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the british empire and the french republic, li...</td>\n",
       "      <td>[the, british, empire, and, the, french, repub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  i have, myself, full confidence that if all do...   \n",
       "1  at any rate, that is what we are going to try ...   \n",
       "2  that is the resolve of his majesty’s governmen...   \n",
       "3     that is the will of parliament and the nation.   \n",
       "4  the british empire and the french republic, li...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [i, have, ,, myself, ,, full, confidence, that...  \n",
       "1  [at, any, rate, ,, that, is, what, we, are, go...  \n",
       "2  [that, is, the, resolve, of, his, majesty’s, g...  \n",
       "3  [that, is, the, will, of, parliament, and, the...  \n",
       "4  [the, british, empire, and, the, french, repub...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Complete this part\n",
    "def parse_speech_to_sentences(fp):\n",
    "    speech = open(fp).read().lower()\n",
    "    rows = []\n",
    "    sent_id = 0\n",
    "\n",
    "    for sent in sent_tokenize(speech):\n",
    "        d = {'sentence':sent, 'tokens': word_tokenize(sent)}\n",
    "        rows.append(d)\n",
    "            \n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "sentence_df_1 = parse_speech_to_sentences('speeches/Churchill-Beaches.txt').head()\n",
    "sentence_df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2\n",
    "   First, write a function called ```get_tokens``` that, given a DataFrame and a column name, converts the column name to a list a returns the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tokens(df, args):\n",
    "    tokens = df[args].tolist()\n",
    "    sentence = ' '.join(tokens)\n",
    "    return pd.Series({'tokens': tokens, 'sentence':sentence})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, take the first DataFrame we made, ```parsed_speech```, and group it by the ```sent_id```.  Then use the DataFrame's ```apply``` method to apply the get_tokens function.  Assign the resulting DataFrame to the variable ```sentence_df_2```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>i have , myself , full confidence that if all ...</td>\n",
       "      <td>[i, have, ,, myself, ,, full, confidence, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>at any rate , that is what we are going to try...</td>\n",
       "      <td>[at, any, rate, ,, that, is, what, we, are, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>that is the resolve of his majesty’s governmen...</td>\n",
       "      <td>[that, is, the, resolve, of, his, majesty’s, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>that is the will of parliament and the nation .</td>\n",
       "      <td>[that, is, the, will, of, parliament, and, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>the british empire and the french republic , l...</td>\n",
       "      <td>[the, british, empire, and, the, french, repub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id                                           sentence  \\\n",
       "0        1  i have , myself , full confidence that if all ...   \n",
       "1        2  at any rate , that is what we are going to try...   \n",
       "2        3  that is the resolve of his majesty’s governmen...   \n",
       "3        4    that is the will of parliament and the nation .   \n",
       "4        5  the british empire and the french republic , l...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [i, have, ,, myself, ,, full, confidence, that...  \n",
       "1  [at, any, rate, ,, that, is, what, we, are, go...  \n",
       "2  [that, is, the, resolve, of, his, majesty’s, g...  \n",
       "3  [that, is, the, will, of, parliament, and, the...  \n",
       "4  [the, british, empire, and, the, french, repub...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df_2 = parsed_speech.groupby('sent_id').apply(get_tokens, args=('token')).reset_index()\n",
    "sentence_df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One More Step\n",
    "Using either ```sentence_df_1``` or ```sentence_df_2``` (but consistently moving forward), create a new column called num_tokens that stores the number of tokens in each sentence (look at the apply method and how it was used to identify stop words and punctuation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>i have , myself , full confidence that if all ...</td>\n",
       "      <td>[i, have, ,, myself, ,, full, confidence, that...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>at any rate , that is what we are going to try...</td>\n",
       "      <td>[at, any, rate, ,, that, is, what, we, are, go...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>that is the resolve of his majesty’s governmen...</td>\n",
       "      <td>[that, is, the, resolve, of, his, majesty’s, g...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>that is the will of parliament and the nation .</td>\n",
       "      <td>[that, is, the, will, of, parliament, and, the...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>the british empire and the french republic , l...</td>\n",
       "      <td>[the, british, empire, and, the, french, repub...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id                                           sentence  \\\n",
       "0        1  i have , myself , full confidence that if all ...   \n",
       "1        2  at any rate , that is what we are going to try...   \n",
       "2        3  that is the resolve of his majesty’s governmen...   \n",
       "3        4    that is the will of parliament and the nation .   \n",
       "4        5  the british empire and the french republic , l...   \n",
       "\n",
       "                                              tokens  num_tokens  \n",
       "0  [i, have, ,, myself, ,, full, confidence, that...          71  \n",
       "1  [at, any, rate, ,, that, is, what, we, are, go...          15  \n",
       "2  [that, is, the, resolve, of, his, majesty’s, g...          12  \n",
       "3  [that, is, the, will, of, parliament, and, the...          10  \n",
       "4  [the, british, empire, and, the, french, repub...          40  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df_2['num_tokens'] = sentence_df_2.tokens.apply(len)\n",
    "sentence_df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the number of tokens in the sentence with the largest number of tokens in the speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df_2.num_tokens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
