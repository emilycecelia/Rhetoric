{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import Counter\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Variables\n",
    "pos_map = {\n",
    "    'CC':'Misc',\n",
    "    'CD':'Adjective',\n",
    "    'DT':'Determiner',\n",
    "    'EX':'Existential',\n",
    "    'FW':'Foreign',\n",
    "    'IN':'Misc',\n",
    "    'JJ':'Adjective',\n",
    "    'JJR':'Adjective',\n",
    "    'JJS':'Adjective',\n",
    "    'MD':'Verb',\n",
    "    'NN':'Noun',\n",
    "    'NNS':'Noun',\n",
    "    'NNP':'Noun',\n",
    "    'NNPS':'Noun',\n",
    "    'PDT':'Determiner',\n",
    "    'POS':'Misc',\n",
    "    'PRP':'Pronoun',\n",
    "    'PRP$':'Pronoun',\n",
    "    'RB':'Adverb',\n",
    "    'RBR':'Adverb',\n",
    "    'RBS':'Adverb',\n",
    "    'RP':'Adverb',\n",
    "    'SYM':'Misc',\n",
    "    'TO':'Misc',\n",
    "    'UH':'Misc',\n",
    "    'VB':'Verb',\n",
    "    'VBZ':'Verb',\n",
    "    'VBP':'Verb',\n",
    "    'VBD':'Verb',\n",
    "    'VBN':'Verb',\n",
    "    'VBG':'Verb',\n",
    "    'WDT':'Determiner',\n",
    "    'WP':'Pronoun',\n",
    "    'WP$':'Pronoun',\n",
    "    'WRB':'Adverb',\n",
    "    '.':'.',\n",
    "    ',':'.',\n",
    "    ':':'.',\n",
    "    '(':'Misc',\n",
    "    ')':'Misc',\n",
    "    \"''\":'Misc',\n",
    "    \"``\":'Misc',\n",
    "    '$':'Misc',\n",
    "}\n",
    "\n",
    "intensifiers = ['amazingly', 'astoundingly', 'dreadfully', 'colossally', 'especially', 'exceptionally',\n",
    "                'excessively', 'extremely', 'extraordinarily', 'fantastically', 'frightfully', 'fully', \n",
    "                'incredibly', 'literally', 'mightily', 'moderately', 'most', 'outrageously', \n",
    "                'phenomenally', 'quite', 'radically', 'rather', 'real', 'really', 'remarkably', 'right', \n",
    "                'somewhat', 'strikingly', 'super', 'supremely', 'surpassingly', 'terribly', \n",
    "                'terrifically', 'too', 'totally', 'uncommonly', 'unusually', 'veritable', 'very']\n",
    "    \n",
    "pronouns = ['ourselves', 'she', 'themselves', 'you', 'ours', 'it', 'yourself', 'yourselves', \n",
    "                'itself', 'my', 'hers', 'her', 'theirs', 'we', 'i', 'me', 'myself', 'your', 'yours', \n",
    "                'them', 'our', 'himself', 'his', 'their', 'they', 'mine', 'herself', 'us', 'its', 'he', 'him']\n",
    "    \n",
    "similarity_clauses = ['in the first place', 'not only', 'as a matter of fact', 'in like manner', 'in addition',\n",
    "                      'coupled with', 'in the same fashion', 'in the same way', 'first, second, third', \n",
    "                      'in the light of', 'not to mention', 'to say nothing of', 'equally important', \n",
    "                      'by the same token', 'again', 'equally', 'identically', \n",
    "                      'uniquely', 'like', 'too', 'moreover', 'as well as', 'together with', 'of course', \n",
    "                      'likewise', 'comparatively', 'correspondingly', 'similarly', 'furthermore', 'additionally']\n",
    "\n",
    "opposition_clauses = ['although this may be true', 'in contrast', 'different from', 'on the other hand', \n",
    "                          'on the contrary', 'at the same time', 'in spite of', 'even so', 'even though', \n",
    "                          'be that as it may', 'then again', 'above all', 'in reality', 'after all', 'but', \n",
    "                          'and still', 'unlike', 'and yet', 'while', 'albeit', 'besides', 'as much as', \n",
    "                          'even though', 'although', 'instead', 'whereas', 'despite', 'conversely', 'otherwise', \n",
    "                          'however', 'rather', 'nevertheless', 'nonetheless', 'regardless', 'notwithstanding']\n",
    "\n",
    "conditional_clauses = ['in the event that', 'granted that', 'as long as', 'so long as', 'for the purpose of', \n",
    "                           'with this intention', 'with this in mind', 'in the hope that', 'to the end that', \n",
    "                           'for fear that', 'in order to', 'seeing that', 'being that', 'in view of', 'unless', \n",
    "                           'when', 'whenever', 'while', 'because of', 'while', 'lest', 'in case', \n",
    "                           'provided that', 'given that', 'only if', 'even if', 'so that', 'so as to', 'owing to', \n",
    "                           'inasmuch as', 'due to']\n",
    "\n",
    "example_clauses = ['in other words', 'to put it differently', 'for one thing', 'as an illustration', 'in this case', \n",
    "                'for this reason', 'to put it another way', 'that is to say', 'with attention to', 'by all means', \n",
    "                'important to realize', 'another key point', 'first thing to remember', 'most compelling evidence', \n",
    "                'must be remembered', 'point often overlooked', 'to point out', 'on the positive side', \n",
    "                'on the negative side', 'with this in mind', 'notably', 'including', 'like', 'to be sure', 'namely', \n",
    "                'chiefly', 'truly', 'indeed', 'certainly', 'surely', 'markedly', 'such as', 'especially', 'explicitly', \n",
    "                'specifically', 'expressly', 'surprisingly', 'frequently', 'significantly', 'particularly', 'in fact', \n",
    "                'in general', 'in particular', 'in detail', 'for example', 'for instance', 'to demonstrate', \n",
    "                'to emphasize', 'to repeat', 'to clarify', 'to explain', 'to enumerate']\n",
    "\n",
    "result_clauses = ['as a result', 'under those circumstances', 'in that case', 'for this reason', 'in effect', \n",
    "                      'thus', 'because the', 'hence', 'consequently', 'therefore', 'thereupon', \n",
    "                      'forthwith', 'accordingly', 'henceforth']\n",
    "\n",
    "conclusion_clauses = ['as a result', 'under those circumstances', 'in that case', 'for this reason', \n",
    "                          'in effect', ', for', 'thus', 'because the', 'then', 'hence', 'consequently', 'therefore', \n",
    "                          'thereupon', 'forthwith', 'accordingly', 'henceforth']\n",
    "\n",
    "sequence_clauses = ['at the present time', 'from time to time', 'sooner or later', 'at the same time',\n",
    "                        'up to the present time', 'to begin with', 'in due time', 'as soon as', 'as long as',\n",
    "                        'in the meantime', 'in a moment', 'without delay', 'in the first place', 'all of a sudden',\n",
    "                        'at this instant', 'first', 'second ', 'immediately', 'quickly', 'finally', 'after', 'later',\n",
    "                        'last', 'until', 'till', 'since', 'then', 'before', 'hence', 'since', 'when', 'once', 'about',\n",
    "                        'next', 'now', 'formerly', 'suddenly', 'shortly', 'henceforth', 'whenever', 'eventually',\n",
    "                        'meanwhile', 'further', 'during', 'in time', 'prior to', 'forthwith', 'straightaway ',\n",
    "                        'by the time', 'whenever ', 'until now', 'now that ', 'instantly', 'presently', 'occasionally']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Utilities\n",
    "def is_stopword(token):\n",
    "    stops = stopwords.words('english').copy()\n",
    "    return token in stops\n",
    "\n",
    "def is_punctuation(token):\n",
    "    return token in string.punctuation\n",
    "\n",
    "def is_vowel(char):\n",
    "    if char in ('a','e','i','o','u','y'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "####Rhetorical Devices\n",
    "\n",
    "##Rhetorical Question\n",
    "def is_rhetorical(sent):\n",
    "    if sent.endswith('?'):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "##Epitrophe\n",
    "#takes tokens\n",
    "def has_epitrophe(tokens):\n",
    "    epitrophe_instances = []\n",
    "\n",
    "    word_dist = Counter(tokens)\n",
    "    repeated_words = [word for word,count in word_dist.items() if count > 1]\n",
    "    \n",
    "    trigrams = nltk.ngrams(tokens,3)\n",
    "    for word in repeated_words:\n",
    "        anchor = None\n",
    "        for trigram in trigrams:\n",
    "            if trigram[1] == word:\n",
    "                tags = nltk.pos_tag(trigram)\n",
    "                if anchor:\n",
    "                    if tags[0][1] == anchor[0][1]:\n",
    "                        epitrophe_instances.append((tuple([word for word,pos in anchor]), trigram))\n",
    "                else:\n",
    "                    anchor = tags\n",
    "    return len(epitrophe_instances)  \n",
    "\n",
    "##Alliteration\n",
    "def has_alliteration(word1, word2):\n",
    "    gram00 = word1[0]\n",
    "    gram10 = word2[0]\n",
    "    \n",
    "    if gram00==gram10:\n",
    "        if is_vowel(gram00):\n",
    "            return True\n",
    "        else:\n",
    "            if len(word1) > 1 and len(word2) > 1:\n",
    "                gram01 = word1[1]\n",
    "                gram11 = word2[1]\n",
    "                if is_vowel(gram01) and is_vowel(gram11):\n",
    "                    return (word1, word2)\n",
    "                elif gram01 == gram11:\n",
    "                    return (word1, word2)\n",
    "    return None\n",
    "\n",
    "#takes tokens\n",
    "def count_alliteration(tokens):\n",
    "    allit_instances = []\n",
    "    #ignore stopwords\n",
    "    tokens = [token for token in tokens if not(is_punctuation(token) or is_stopword(token))]\n",
    "    \n",
    "    bigrams = nltk.ngrams(tokens,2)\n",
    "    for one,two in bigrams:\n",
    "        if has_alliteration(one,two):\n",
    "            allit_instances.append((one,two))\n",
    "    trigrams = nltk.ngrams(tokens,3)\n",
    "    for one,two,three in trigrams:\n",
    "        #the not avoids double counting\n",
    "        if has_alliteration(one,three) and not has_alliteration(one,two):\n",
    "            allit_instances.append((one,two,three))\n",
    "    return len(allit_instances)\n",
    "\n",
    "####Clauses\n",
    "#Note: certain clauses are in multiple lists, thus there will be double counting\n",
    "def contains_patterns(sent, pattern_list):\n",
    "    for pattern in pattern_list:\n",
    "        pattern = '(^%s)|(\\s%s\\s)' % (pattern,pattern,)\n",
    "        m = re.search(pattern, sent)\n",
    "        if m:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_sentence(sent):\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    \n",
    "    #Rhetorical Devices\n",
    "    rhetoric = is_rhetorical(sent)\n",
    "    epitrophe = has_epitrophe(tokens)\n",
    "    alliteration = count_alliteration(tokens)\n",
    "    \n",
    "    #Clauses\n",
    "    similarity = contains_patterns(sent, similarity_clauses)\n",
    "    opposition = contains_patterns(sent, opposition_clauses)\n",
    "    conditional = contains_patterns(sent, conditional_clauses)\n",
    "    example = contains_patterns(sent, example_clauses)\n",
    "    result = contains_patterns(sent, result_clauses)\n",
    "    conclusion = contains_patterns(sent, result_clauses)\n",
    "    sequence = contains_patterns(sent, sequence_clauses)\n",
    "    \n",
    "    #Distributions\n",
    "    #pos_highlevel_dist = # \n",
    "    #pronouns_dist = #\n",
    "    \n",
    "    attr_dict = {\n",
    "        'rhetoric_count': rhetoric,\n",
    "        'epitrophe_count': epitrophe,\n",
    "        'alliteration_count': alliteration,\n",
    "        'similarity_count': similarity,\n",
    "        'opposition_count': opposition,\n",
    "        'conditional_count': conditional,\n",
    "        'example_count': example,\n",
    "        'result_count': result,\n",
    "        'conclusion_count': conclusion,\n",
    "        'sequence_count': sequence,\n",
    "        'sentence_length': len(tokens),\n",
    "    }\n",
    "    \n",
    "    return attr_dict\n",
    "    \n",
    "def evaluate_speech(speech_str):\n",
    "    speech = speech_str.lower()\n",
    "    \n",
    "    #Token features\n",
    "    speech_tokens = nltk.word_tokenize(speech)\n",
    "    tokens_no_stop = [token for token in speech_tokens if not (is_stopword(token) or is_punctuation(token))]\n",
    "    num_tokens = len(tokens_no_stop)\n",
    "    num_unique_tokens = len(set(tokens_no_stop))\n",
    "    diversity = num_unique_tokens/num_tokens\n",
    "    avg_token_length = sum([len(token) for token in tokens_no_stop])/num_tokens\n",
    "    \n",
    "    #Sentence features\n",
    "    sentence_attrs = []\n",
    "    for sentence in nltk.sent_tokenize(speech):\n",
    "        attrs = evaluate_sentence(sentence)\n",
    "        sentence_attrs.append(attrs)\n",
    "    sentence_attrs = pd.DataFrame(sentence_attrs)\n",
    "    sentence_features = sentence_attrs.sum()\n",
    "    sentence_length = sentence_features['sentence_length']\n",
    "    sentence_features = sentence_features/num_tokens\n",
    "\n",
    "    sentence_features['sentence_length'] = sentence_length.sum()/len(sentence_attrs)\n",
    "    sentence_features['diversity'] = diversity\n",
    "    sentence_features['token_length'] = avg_token_length\n",
    "    \n",
    "    return sentence_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alliteration_count     0.075601\n",
       "conclusion_count       0.000000\n",
       "conditional_count      0.003436\n",
       "epitrophe_count        0.041237\n",
       "example_count          0.000000\n",
       "opposition_count       0.010309\n",
       "result_count           0.000000\n",
       "rhetoric_count         0.006873\n",
       "sentence_length       19.388889\n",
       "sequence_count         0.027491\n",
       "similarity_count       0.006873\n",
       "diversity              0.773196\n",
       "token_length           6.271478\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = 'speeches/Churchill-Blood.txt'\n",
    "speech = open(fp).read().lower()\n",
    "s = evaluate_speech(speech)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
