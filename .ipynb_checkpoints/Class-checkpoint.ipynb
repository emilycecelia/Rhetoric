{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ourselves', 'she', 'themselves', 'you', 'ours', 'it', 'yourself', 'yourselves', 'itself', 'my', 'hers', 'her', 'theirs', 'we', 'i', 'me', 'myself', 'your', 'yours', 'them', 'our', 'himself', 'his', 'their', 'they', 'mine', 'herself', 'us', 'its', 'he', 'him']\n",
      "35\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "l = ['i', 'me', 'you', 'she', 'her', 'he', 'him', 'it', 'we', 'us', 'they', \n",
    "                'them', 'myself', 'yourself', 'himself', 'herself', 'itself', 'ourselves', \n",
    "                'yourselves', 'themselves', 'my', 'your', 'his', 'her', 'its', 'mine', 'yours', \n",
    "                'his', 'hers', 'our', 'your', 'their', 'ours', 'yours', 'theirs']\n",
    "s = list(set(l))\n",
    "print(s)\n",
    "print(len(l))\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['has_conclusion', 'has_conditional', 'has_example', 'has_opposition', 'has_result', 'has_sequence', 'has_similarity', 'has_parallel', 'alliteration_count', 'intensifier_count', 'is_question', 'he', 'her', 'hers', 'herself', 'him', 'himself', 'his', 'i', 'it', 'its', 'itself', 'me', 'mine', 'my', 'myself', 'our', 'ours', 'ourselves', 'she', 'their', 'theirs', 'them', 'themselves', 'they', 'us', 'we', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag, ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def get_tokens_as_list(df, args):\n",
    "    values = df[args].tolist()\n",
    "    return values\n",
    "\n",
    "def concat_vals(ser):\n",
    "    vals = ser.tolist()\n",
    "    return ' '.join(vals)\n",
    "\n",
    "def is_stopword(token):\n",
    "    stops = stopwords.words('english').copy()\n",
    "    return token in stops\n",
    "\n",
    "def is_punctuation(token):\n",
    "    return token in string.punctuation\n",
    "\n",
    "def is_vowel(char):\n",
    "    if char in ('a','e','i','o','u','y'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def has_alliteration(word1, word2):\n",
    "    gram00 = word1[0]\n",
    "    gram10 = word2[0]\n",
    "    \n",
    "    if gram00==gram10:\n",
    "        if is_vowel(gram00):\n",
    "            return True\n",
    "        else:\n",
    "            if len(word1) > 1 and len(word2) > 1:\n",
    "                gram01 = word1[1]\n",
    "                gram11 = word2[1]\n",
    "                if is_vowel(gram01) and is_vowel(gram11):\n",
    "                    return True\n",
    "                elif gram01 == gram11:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def is_question(tokens):\n",
    "    if tokens[-1] == '?':\n",
    "        return 1\n",
    "    return 0\n",
    "        \n",
    "\n",
    "class Speech():\n",
    "    parallel_p = re.compile('(\\w+\\s,\\s){2,}((\\w+\\sand\\s\\w+)|(and\\s\\w+))')\n",
    "    \n",
    "    intensifiers = ['amazingly', 'astoundingly', 'dreadfully', 'colossally', 'especially', 'exceptionally',\n",
    "                'excessively', 'extremely', 'extraordinarily', 'fantastically', 'frightfully', 'fully', \n",
    "                'incredibly', 'literally', 'mightily', 'moderately', 'most', 'outrageously', \n",
    "                'phenomenally', 'quite', 'radically', 'rather', 'real', 'really', 'remarkably', 'right', \n",
    "                'somewhat', 'strikingly', 'super', 'supremely', 'surpassingly', 'terribly', \n",
    "                'terrifically', 'too', 'totally', 'uncommonly', 'unusually', 'veritable', 'very']\n",
    "    \n",
    "    pronouns = ['ourselves', 'she', 'themselves', 'you', 'ours', 'it', 'yourself', 'yourselves', \n",
    "                'itself', 'my', 'hers', 'her', 'theirs', 'we', 'i', 'me', 'myself', 'your', 'yours', \n",
    "                'them', 'our', 'himself', 'his', 'their', 'they', 'mine', 'herself', 'us', 'its', 'he', 'him']\n",
    "    \n",
    "    similarity_clauses = ['in the first place', 'not only', 'as a matter of fact', 'in like manner', 'in addition',\n",
    "                      'coupled with', 'in the same fashion', 'in the same way', 'first, second, third', \n",
    "                      'in the light of', 'not to mention', 'to say nothing of', 'equally important', \n",
    "                      'by the same token', 'again', 'equally', 'identically', \n",
    "                      'uniquely', 'like', 'too', 'moreover', 'as well as', 'together with', 'of course', \n",
    "                      'likewise', 'comparatively', 'correspondingly', 'similarly', 'furthermore', 'additionally']\n",
    "\n",
    "    opposition_clauses = ['although this may be true', 'in contrast', 'different from', 'on the other hand', \n",
    "                          'on the contrary', 'at the same time', 'in spite of', 'even so', 'even though', \n",
    "                          'be that as it may', 'then again', 'above all', 'in reality', 'after all', 'but', \n",
    "                          'and still', 'unlike', 'and yet', 'while', 'albeit', 'besides', 'as much as', \n",
    "                          'even though', 'although', 'instead', 'whereas', 'despite', 'conversely', 'otherwise', \n",
    "                          'however', 'rather', 'nevertheless', 'nonetheless', 'regardless', 'notwithstanding']\n",
    "\n",
    "    conditional_clauses = ['in the event that', 'granted that', 'as long as', 'so long as', 'for the purpose of', \n",
    "                           'with this intention', 'with this in mind', 'in the hope that', 'to the end that', \n",
    "                           'for fear that', 'in order to', 'seeing that', 'being that', 'in view of', 'unless', \n",
    "                           'when', 'whenever', 'while', 'because of', 'while', 'lest', 'in case', \n",
    "                           'provided that', 'given that', 'only if', 'even if', 'so that', 'so as to', 'owing to', \n",
    "                           'inasmuch as', 'due to']\n",
    "\n",
    "    example_clauses = ['in other words', 'to put it differently', 'for one thing', 'as an illustration', 'in this case', \n",
    "                'for this reason', 'to put it another way', 'that is to say', 'with attention to', 'by all means', \n",
    "                'important to realize', 'another key point', 'first thing to remember', 'most compelling evidence', \n",
    "                'must be remembered', 'point often overlooked', 'to point out', 'on the positive side', \n",
    "                'on the negative side', 'with this in mind', 'notably', 'including', 'like', 'to be sure', 'namely', \n",
    "                'chiefly', 'truly', 'indeed', 'certainly', 'surely', 'markedly', 'such as', 'especially', 'explicitly', \n",
    "                'specifically', 'expressly', 'surprisingly', 'frequently', 'significantly', 'particularly', 'in fact', \n",
    "                'in general', 'in particular', 'in detail', 'for example', 'for instance', 'to demonstrate', \n",
    "                'to emphasize', 'to repeat', 'to clarify', 'to explain', 'to enumerate']\n",
    "\n",
    "    result_clauses = ['as a result', 'under those circumstances', 'in that case', 'for this reason', 'in effect', \n",
    "                      'thus', 'because the', 'hence', 'consequently', 'therefore', 'thereupon', \n",
    "                      'forthwith', 'accordingly', 'henceforth']\n",
    "\n",
    "    conclusion_clauses = ['as a result', 'under those circumstances', 'in that case', 'for this reason', \n",
    "                          'in effect', ', for', 'thus', 'because the', 'then', 'hence', 'consequently', 'therefore', \n",
    "                          'thereupon', 'forthwith', 'accordingly', 'henceforth']\n",
    "\n",
    "    sequence_clauses = ['at the present time', 'from time to time', 'sooner or later', 'at the same time',\n",
    "                        'up to the present time', 'to begin with', 'in due time', 'as soon as', 'as long as',\n",
    "                        'in the meantime', 'in a moment', 'without delay', 'in the first place', 'all of a sudden',\n",
    "                        'at this instant', 'first', 'second ', 'immediately', 'quickly', 'finally', 'after', 'later',\n",
    "                        'last', 'until', 'till', 'since', 'then', 'before', 'hence', 'since', 'when', 'once', 'about',\n",
    "                        'next', 'now', 'formerly', 'suddenly', 'shortly', 'henceforth', 'whenever', 'eventually',\n",
    "                        'meanwhile', 'further', 'during', 'in time', 'prior to', 'forthwith', 'straightaway ',\n",
    "                        'by the time', 'whenever ', 'until now', 'now that ', 'instantly', 'presently', 'occasionally']\n",
    "    \n",
    "    def __init__(self, low_string):\n",
    "        self.string = low_string\n",
    "        self.tokens = self.make_token_df()\n",
    "        self.sentences = self.make_sent_df()\n",
    "        self.metrics = self.make_metrics()\n",
    "        \n",
    "    def make_token_df(self):\n",
    "        rows = []\n",
    "        sent_id = 0\n",
    "        for sentence in sent_tokenize(self.string):\n",
    "            for word in word_tokenize(sentence):\n",
    "                info = {'token':word, 'sent_id':sent_id}\n",
    "                rows.append(info)\n",
    "            sent_id += 1\n",
    "        parsed_speech = pd.DataFrame(rows)\n",
    "        parsed_speech['is_stop'] = parsed_speech.token.apply(is_stopword)\n",
    "        parsed_speech['is_punct'] = parsed_speech['token'].apply(is_punctuation)\n",
    "        \n",
    "        pos_tags = pos_tag(parsed_speech.token.tolist())\n",
    "        just_tags = [x[1] for x in pos_tags]\n",
    "        parsed_speech['pos'] = pd.Series( just_tags )\n",
    "\n",
    "        return parsed_speech\n",
    "        \n",
    "    def make_sent_df(self):\n",
    "        speech_sentences = self.tokens.groupby('sent_id').apply(get_tokens_as_list, args=('token'))\n",
    "        speech_tags = self.tokens.groupby('sent_id').apply(get_tokens_as_list, args=('pos'))\n",
    "        speech_sentences = pd.concat([speech_sentences,speech_tags], axis=1).reset_index()\n",
    "        speech_sentences.columns = ['sent_id','tokens','pos_pattern']\n",
    "        speech_sentences['sentence'] = speech_sentences['tokens'].apply(' '.join)\n",
    "        speech_sentences['num_tokens'] = speech_sentences['tokens'].apply(len)\n",
    "        speech_sentences = pd.concat([speech_sentences, speech_sentences.sentence.apply(self.identify_clauses)], axis=1)\n",
    "        speech_sentences['has_parallel'] = speech_sentences.sentence.apply(self.contains_parallel)\n",
    "        speech_sentences['alliteration_count'] = speech_sentences.tokens.apply(self.count_alliteration)\n",
    "        speech_sentences['intensifier_count'] = speech_sentences.tokens.apply(self.count_intensifiers)\n",
    "        speech_sentences['is_question'] = speech_sentences.tokens.apply(is_question)\n",
    "        pronouns = speech_sentences.apply(self.count_pronouns, axis=1)\n",
    "        speech_sentences = pd.concat([speech_sentences,pronouns], axis=1)\n",
    "        return speech_sentences\n",
    "    \n",
    "    def make_metrics(self):\n",
    "        metric_columns = [x for x in self.sentences.columns if x not in ['sent_id', 'tokens', 'pos_pattern', 'sentence', 'num_tokens']]\n",
    "        return self.sentences[metric_columns].sum()/len(self.sentences)\n",
    "    \n",
    "    def __contains_clause__(self, s, args):\n",
    "        patterns = args\n",
    "        for pattern in patterns:\n",
    "            pattern = '(^%s)|(\\s%s\\s)' % (pattern,pattern,)\n",
    "            m = re.search(pattern, s)\n",
    "            if m:\n",
    "                return 1\n",
    "        return 0\n",
    "    \n",
    "    def identify_clauses(self, s):\n",
    "        similarity = self.__contains_clause__(s, Speech.similarity_clauses)#contains_similarity_clause(s)\n",
    "        opposition = self.__contains_clause__(s, Speech.opposition_clauses)\n",
    "        conditional = self.__contains_clause__(s, Speech.conditional_clauses)\n",
    "        example = self.__contains_clause__(s, Speech.example_clauses)\n",
    "        result = self.__contains_clause__(s, Speech.result_clauses)\n",
    "        conclusion = self.__contains_clause__(s, Speech.conclusion_clauses)\n",
    "        sequence = self.__contains_clause__(s, Speech.sequence_clauses)\n",
    "\n",
    "        d = dict(has_similarity=similarity, has_opposition=opposition, has_conditional=conditional,\n",
    "                has_example=example, has_result=result, has_conclusion=conclusion, has_sequence=sequence)\n",
    "\n",
    "        return pd.Series(d)  \n",
    "    \n",
    "    def contains_parallel(self, s):\n",
    "        m = re.search(Speech.parallel_p,s)\n",
    "        if m:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def count_pronouns(self, ser):\n",
    "        tokens = ser['tokens']\n",
    "        pronoun_dict = {}\n",
    "        for pronoun in Speech.pronouns:\n",
    "            pronoun_dict.setdefault(pronoun,0)\n",
    "        for token in tokens:\n",
    "            if token in Speech.pronouns:\n",
    "                pronoun_dict[token] = 1\n",
    "        return pd.Series(pronoun_dict)\n",
    "    \n",
    "    def count_alliteration(self, tokens):\n",
    "        allit_count = 0\n",
    "        bigrams = ngrams(tokens, 2)\n",
    "        for bigram in bigrams:\n",
    "            if has_alliteration(bigram[0],bigram[1]):\n",
    "                allit_count += 1      \n",
    "        trigrams = ngrams(tokens, 3)\n",
    "        for trigram in trigrams:\n",
    "            if has_alliteration(trigram[0],trigram[2]):\n",
    "                allit_count += 1\n",
    "                \n",
    "        if allit_count > 0:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def count_intensifiers(self, tokens):\n",
    "        count = 0\n",
    "        for token in tokens:\n",
    "            if token in Speech.intensifiers:\n",
    "                count = 1\n",
    "        return count\n",
    "\n",
    "fp = 'speeches/FDR-PearlHarbor.txt'\n",
    "text = open(fp).read().lower()       \n",
    "test = Speech(text)\n",
    "\n",
    "print(test.metrics.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Churchill-Beaches.txt',\n",
       " 'Churchill-Blood.txt',\n",
       " 'Churchill-EveryMan.txt',\n",
       " 'FDR-FourFreedoms.txt',\n",
       " 'FDR-Inaugural.txt',\n",
       " 'FDR-PearlHarbor.txt',\n",
       " 'JFK-CityOnHill.txt',\n",
       " 'JFK-Houston.txt',\n",
       " 'JFK-Inaugural.txt',\n",
       " 'LBJ-WeShallOvercome.txt',\n",
       " 'MalcolmX-BallotBullet.txt',\n",
       " 'MLKJ-IHaveADream.txt',\n",
       " 'MLKJ-Mountaintop.txt',\n",
       " 'Nixon-Checkers.txt',\n",
       " 'Reagan-Challenger.txt']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('speeches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(Speech.pronouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>has_conclusion</th>\n",
       "      <th>has_conditional</th>\n",
       "      <th>has_example</th>\n",
       "      <th>has_opposition</th>\n",
       "      <th>has_result</th>\n",
       "      <th>has_sequence</th>\n",
       "      <th>has_similarity</th>\n",
       "      <th>has_parallel</th>\n",
       "      <th>...</th>\n",
       "      <th>himself</th>\n",
       "      <th>his</th>\n",
       "      <th>their</th>\n",
       "      <th>they</th>\n",
       "      <th>mine</th>\n",
       "      <th>herself</th>\n",
       "      <th>us</th>\n",
       "      <th>its</th>\n",
       "      <th>he</th>\n",
       "      <th>him</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Churchill</td>\n",
       "      <td>Beaches</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Churchill</td>\n",
       "      <td>Blood</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Churchill</td>\n",
       "      <td>EveryMan</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDR</td>\n",
       "      <td>FourFreedoms</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.087838</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.209459</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDR</td>\n",
       "      <td>Inaugural</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.131868</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.175824</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.120879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FDR</td>\n",
       "      <td>PearlHarbor</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JFK</td>\n",
       "      <td>CityOnHill</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JFK</td>\n",
       "      <td>Houston</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JFK</td>\n",
       "      <td>Inaugural</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker          name  has_conclusion  has_conditional  has_example  \\\n",
       "0  Churchill       Beaches        0.142857         0.142857     0.142857   \n",
       "1  Churchill         Blood        0.055556         0.027778     0.000000   \n",
       "2  Churchill      EveryMan        0.105263         0.157895     0.105263   \n",
       "3        FDR  FourFreedoms        0.040541         0.087838     0.033784   \n",
       "4        FDR     Inaugural        0.043956         0.021978     0.010989   \n",
       "5        FDR   PearlHarbor        0.038462         0.076923     0.038462   \n",
       "6        JFK    CityOnHill        0.029412         0.058824     0.205882   \n",
       "7        JFK       Houston        0.133333         0.111111     0.088889   \n",
       "8        JFK     Inaugural        0.038462         0.019231     0.038462   \n",
       "\n",
       "   has_opposition  has_result  has_sequence  has_similarity  has_parallel  \\\n",
       "0        0.142857    0.000000      0.285714        0.285714      0.000000   \n",
       "1        0.083333    0.000000      0.250000        0.055556      0.083333   \n",
       "2        0.342105    0.078947      0.368421        0.105263      0.026316   \n",
       "3        0.081081    0.033784      0.209459        0.033784      0.006757   \n",
       "4        0.131868    0.021978      0.175824        0.032967      0.000000   \n",
       "5        0.115385    0.038462      0.346154        0.076923      0.000000   \n",
       "6        0.147059    0.000000      0.264706        0.147059      0.029412   \n",
       "7        0.355556    0.000000      0.244444        0.133333      0.044444   \n",
       "8        0.288462    0.019231      0.230769        0.038462      0.019231   \n",
       "\n",
       "     ...      himself       his     their      they      mine  herself  \\\n",
       "0    ...     0.000000  0.142857  0.285714  0.142857  0.000000      0.0   \n",
       "1    ...     0.000000  0.055556  0.000000  0.000000  0.000000      0.0   \n",
       "2    ...     0.052632  0.105263  0.105263  0.157895  0.000000      0.0   \n",
       "3    ...     0.000000  0.006757  0.108108  0.081081  0.000000      0.0   \n",
       "4    ...     0.010989  0.010989  0.098901  0.120879  0.000000      0.0   \n",
       "5    ...     0.000000  0.038462  0.076923  0.000000  0.000000      0.0   \n",
       "6    ...     0.000000  0.058824  0.058824  0.117647  0.000000      0.0   \n",
       "7    ...     0.000000  0.088889  0.088889  0.111111  0.000000      0.0   \n",
       "8    ...     0.000000  0.038462  0.038462  0.019231  0.019231      0.0   \n",
       "\n",
       "         us       its        he       him  \n",
       "0  0.000000  0.142857  0.000000  0.000000  \n",
       "1  0.111111  0.027778  0.000000  0.000000  \n",
       "2  0.052632  0.052632  0.131579  0.026316  \n",
       "3  0.067568  0.040541  0.000000  0.000000  \n",
       "4  0.054945  0.010989  0.032967  0.000000  \n",
       "5  0.153846  0.038462  0.000000  0.000000  \n",
       "6  0.117647  0.088235  0.029412  0.000000  \n",
       "7  0.000000  0.044444  0.022222  0.088889  \n",
       "8  0.192308  0.096154  0.000000  0.000000  \n",
       "\n",
       "[9 rows x 44 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['speaker','name','has_conclusion', 'has_conditional', 'has_example', 'has_opposition', \n",
    "                           'has_result', 'has_sequence', 'has_similarity', 'has_parallel', 'intensifier_count', \n",
    "                           'is_question', 'alliteration_count']+Speech.pronouns)\n",
    "for fn in os.listdir('speeches'):\n",
    "    if fn.endswith('.txt'):\n",
    "        speaker,name=fn.rstrip('.txt').split('-')\n",
    "        if speaker in ['JFK','FDR','Churchill']:\n",
    "            fp = 'speeches/' + fn\n",
    "            text = open(fp).read().lower()\n",
    "            speech = Speech(text)\n",
    "            metrics = speech.metrics\n",
    "            metrics['name'] = name\n",
    "            metrics['speaker'] = speaker\n",
    "            df.loc[len(df)] = metrics\n",
    "\n",
    "df.to_csv('data/speech_metrics.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['speaker', 'name', 'has_conclusion', 'has_conditional', 'has_example',\n",
       "       'has_opposition', 'has_result', 'has_sequence', 'has_similarity',\n",
       "       'has_parallel', 'intensifier_count', 'is_question',\n",
       "       'alliteration_count', 'ourselves', 'she', 'themselves', 'you', 'ours',\n",
       "       'it', 'yourself', 'yourselves', 'itself', 'my', 'hers', 'her', 'theirs',\n",
       "       'we', 'i', 'me', 'myself', 'your', 'yours', 'them', 'our', 'himself',\n",
       "       'his', 'their', 'they', 'mine', 'herself', 'us', 'its', 'he', 'him'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "\n",
    "pronoun_cols = Speech.pronouns\n",
    "clause_cols = ['has_conclusion', 'has_conditional', 'has_example', 'has_opposition', \n",
    "                           'has_result', 'has_sequence', 'has_similarity']\n",
    "technique_cols = ['has_parallel', 'alliteration_count', 'intensifier_count', 'is_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Churchill' 'Beaches']\t1\n",
      "['Churchill' 'Blood']\t0\n",
      "['Churchill' 'EveryMan']\t2\n",
      "['FDR' 'FourFreedoms']\t2\n",
      "['FDR' 'Inaugural']\t2\n",
      "['FDR' 'PearlHarbor']\t2\n",
      "['JFK' 'CityOnHill']\t0\n",
      "['JFK' 'Houston']\t0\n",
      "['JFK' 'Inaugural']\t2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ourselves</th>\n",
       "      <th>she</th>\n",
       "      <th>themselves</th>\n",
       "      <th>you</th>\n",
       "      <th>ours</th>\n",
       "      <th>it</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>itself</th>\n",
       "      <th>my</th>\n",
       "      <th>...</th>\n",
       "      <th>himself</th>\n",
       "      <th>his</th>\n",
       "      <th>their</th>\n",
       "      <th>they</th>\n",
       "      <th>mine</th>\n",
       "      <th>herself</th>\n",
       "      <th>us</th>\n",
       "      <th>its</th>\n",
       "      <th>he</th>\n",
       "      <th>him</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.148475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067756</td>\n",
       "      <td>0.049237</td>\n",
       "      <td>0.076253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076253</td>\n",
       "      <td>0.053486</td>\n",
       "      <td>0.017211</td>\n",
       "      <td>0.029630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>0.041141</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.188121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022459</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012724</td>\n",
       "      <td>0.039986</td>\n",
       "      <td>0.085531</td>\n",
       "      <td>0.075817</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104260</td>\n",
       "      <td>0.047755</td>\n",
       "      <td>0.032909</td>\n",
       "      <td>0.005263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ourselves  she  themselves       you      ours        it  yourself  \\\n",
       "0   0.009804  0.0    0.000000  0.057952  0.000000  0.171242       0.0   \n",
       "1   0.142857  0.0    0.000000  0.000000  0.000000  0.142857       0.0   \n",
       "2   0.020054  0.0    0.017582  0.041141  0.001351  0.188121       0.0   \n",
       "\n",
       "   yourselves    itself        my    ...      himself       his     their  \\\n",
       "0         0.0  0.009259  0.148475    ...     0.000000  0.067756  0.049237   \n",
       "1         0.0  0.000000  0.000000    ...     0.000000  0.142857  0.285714   \n",
       "2         0.0  0.022459  0.037087    ...     0.012724  0.039986  0.085531   \n",
       "\n",
       "       they      mine  herself        us       its        he       him  \n",
       "0  0.076253  0.000000      0.0  0.076253  0.053486  0.017211  0.029630  \n",
       "1  0.142857  0.000000      0.0  0.000000  0.142857  0.000000  0.000000  \n",
       "2  0.075817  0.003846      0.0  0.104260  0.047755  0.032909  0.005263  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cols = ['speaker','name']\n",
    "X = df[pronoun_cols].fillna(0).as_matrix()\n",
    "est = KMeans(n_clusters=3)\n",
    "est.fit(X)\n",
    "labels = est.labels_\n",
    "members = tuple(zip(df[y_cols].as_matrix(),labels))\n",
    "centers = pd.DataFrame(est.cluster_centers_, columns=pronoun_cols)\n",
    "for member, group in members:\n",
    "    print(str(member), group, sep='\\t')\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Churchill' 'Beaches']\t2\n",
      "['Churchill' 'Blood']\t1\n",
      "['Churchill' 'EveryMan']\t0\n",
      "['FDR' 'FourFreedoms']\t1\n",
      "['FDR' 'Inaugural']\t1\n",
      "['FDR' 'PearlHarbor']\t1\n",
      "['JFK' 'CityOnHill']\t2\n",
      "['JFK' 'Houston']\t0\n",
      "['JFK' 'Inaugural']\t0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_conclusion</th>\n",
       "      <th>has_conditional</th>\n",
       "      <th>has_example</th>\n",
       "      <th>has_opposition</th>\n",
       "      <th>has_result</th>\n",
       "      <th>has_sequence</th>\n",
       "      <th>has_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092353</td>\n",
       "      <td>0.096079</td>\n",
       "      <td>0.077538</td>\n",
       "      <td>0.328707</td>\n",
       "      <td>0.032726</td>\n",
       "      <td>0.281212</td>\n",
       "      <td>0.092353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044628</td>\n",
       "      <td>0.053629</td>\n",
       "      <td>0.020809</td>\n",
       "      <td>0.102917</td>\n",
       "      <td>0.023556</td>\n",
       "      <td>0.245359</td>\n",
       "      <td>0.049807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086134</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.174370</td>\n",
       "      <td>0.144958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275210</td>\n",
       "      <td>0.216387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_conclusion  has_conditional  has_example  has_opposition  has_result  \\\n",
       "0        0.092353         0.096079     0.077538        0.328707    0.032726   \n",
       "1        0.044628         0.053629     0.020809        0.102917    0.023556   \n",
       "2        0.086134         0.100840     0.174370        0.144958    0.000000   \n",
       "\n",
       "   has_sequence  has_similarity  \n",
       "0      0.281212        0.092353  \n",
       "1      0.245359        0.049807  \n",
       "2      0.275210        0.216387  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cols = ['speaker','name']\n",
    "X = df[clause_cols].fillna(0).as_matrix()\n",
    "est = KMeans(n_clusters=3)\n",
    "est.fit(X)\n",
    "labels = est.labels_\n",
    "members = tuple(zip(df[y_cols].as_matrix(),labels))\n",
    "centers = pd.DataFrame(est.cluster_centers_, columns=clause_cols)\n",
    "for member, group in members:\n",
    "    print(str(member), group, sep='\\t')\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Churchill' 'Beaches']\t2\n",
      "['Churchill' 'Blood']\t0\n",
      "['Churchill' 'EveryMan']\t1\n",
      "['FDR' 'FourFreedoms']\t0\n",
      "['FDR' 'Inaugural']\t0\n",
      "['FDR' 'PearlHarbor']\t0\n",
      "['JFK' 'CityOnHill']\t0\n",
      "['JFK' 'Houston']\t0\n",
      "['JFK' 'Inaugural']\t0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_parallel</th>\n",
       "      <th>alliteration_count</th>\n",
       "      <th>intensifier_count</th>\n",
       "      <th>is_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026168</td>\n",
       "      <td>0.749701</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>0.029211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_parallel  alliteration_count  intensifier_count  is_question\n",
       "0      0.026168            0.749701           0.068491     0.029211\n",
       "1      0.026316            0.789474           0.315789     0.000000\n",
       "2      0.000000            1.000000           0.000000     0.000000"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cols = ['speaker','name']\n",
    "X = df[technique_cols].fillna(0).as_matrix()\n",
    "est = KMeans(n_clusters=3)\n",
    "est.fit(X)\n",
    "labels = est.labels_\n",
    "members = tuple(zip(df[y_cols].as_matrix(),labels))\n",
    "centers = pd.DataFrame(est.cluster_centers_, columns=technique_cols)\n",
    "for member, group in members:\n",
    "    print(str(member), group, sep='\\t')\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array(['Churchill', 'Beaches'], dtype=object), 2),\n",
       " (array(['Churchill', 'Blood'], dtype=object), 0),\n",
       " (array(['Churchill', 'EveryMan'], dtype=object), 1),\n",
       " (array(['FDR', 'FourFreedoms'], dtype=object), 0),\n",
       " (array(['FDR', 'Inaugural'], dtype=object), 0),\n",
       " (array(['FDR', 'PearlHarbor'], dtype=object), 0),\n",
       " (array(['JFK', 'CityOnHill'], dtype=object), 0),\n",
       " (array(['JFK', 'Houston'], dtype=object), 0),\n",
       " (array(['JFK', 'Inaugural'], dtype=object), 0))"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_parallel</th>\n",
       "      <th>alliteration_count</th>\n",
       "      <th>intensifier_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026168</td>\n",
       "      <td>0.749701</td>\n",
       "      <td>0.068491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_parallel  alliteration_count  intensifier_count\n",
       "0      0.026168            0.749701           0.068491\n",
       "1      0.000000            1.000000           0.000000\n",
       "2      0.026316            0.789474           0.315789"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.94871795e-01,   2.56410256e-02,   5.47008547e-01,\n",
       "          5.98290598e-02,   1.41025641e-01,   0.00000000e+00,\n",
       "          4.27350427e-03,   2.56410256e-02,   2.56410256e-02,\n",
       "          4.27350427e-03,   2.47863248e-01,   0.00000000e+00,\n",
       "          0.00000000e+00,   5.12820513e-02,   4.27350427e-03,\n",
       "          8.54700855e-02,   8.54700855e-03,   2.99145299e-02,\n",
       "          4.27350427e-03,   1.66666667e-01,   0.00000000e+00,\n",
       "          0.00000000e+00,   5.12820513e-02,   5.12820513e-02,\n",
       "          1.41025641e-01,   2.56410256e-02,   5.55555556e-02,\n",
       "          5.98290598e-02,   0.00000000e+00,   2.99145299e-02,\n",
       "          4.27350427e-03,   4.27350427e-03,   0.00000000e+00,\n",
       "          4.27350427e-03,   2.56410256e-02,   2.56410256e-02,\n",
       "          6.41025641e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.53846154e-01,   2.26495726e-01,   5.98290598e-02,\n",
       "          1.70940171e-02],\n",
       "       [  2.80955856e-01,   1.27226463e-03,   1.86547504e-01,\n",
       "          6.18360048e-02,   1.43960628e-01,   9.19595672e-03,\n",
       "          2.35492210e-02,   1.44371005e-02,   1.44371005e-02,\n",
       "          1.85929200e-02,   1.97342616e-01,   0.00000000e+00,\n",
       "          1.61004308e-02,   3.72943148e-02,   1.47772911e-02,\n",
       "          4.66324229e-02,   0.00000000e+00,   1.98903020e-01,\n",
       "          1.35901505e-02,   4.72243301e-02,   9.54198473e-04,\n",
       "          6.36132316e-04,   5.06844229e-02,   5.06844229e-02,\n",
       "          1.57600034e-02,   6.17814829e-02,   7.54606340e-02,\n",
       "          8.13068602e-02,   0.00000000e+00,   7.46719907e-02,\n",
       "          3.18066158e-04,   0.00000000e+00,   2.63444907e-02,\n",
       "          1.59033079e-03,   4.18208831e-03,   4.18208831e-03,\n",
       "          3.54517260e-02,   3.73989878e-03,   3.73989878e-03,\n",
       "          1.81193818e-01,   8.44606807e-02,   4.89332261e-02,\n",
       "          1.36098835e-02],\n",
       "       [  1.45996860e-01,   0.00000000e+00,   1.00274725e-01,\n",
       "          4.98430141e-02,   2.05455259e-01,   1.92307692e-02,\n",
       "          9.61538462e-03,   4.98430141e-02,   4.98430141e-02,\n",
       "          9.61538462e-03,   1.89756672e-01,   0.00000000e+00,\n",
       "          9.61538462e-03,   8.88932496e-02,   0.00000000e+00,\n",
       "          1.02040816e-02,   0.00000000e+00,   2.04866562e-01,\n",
       "          0.00000000e+00,   2.88461538e-02,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.94348509e-02,   2.94348509e-02,\n",
       "          2.04081633e-02,   7.02511774e-02,   9.12480377e-02,\n",
       "          9.61538462e-03,   0.00000000e+00,   1.47174254e-01,\n",
       "          9.61538462e-03,   0.00000000e+00,   5.82810047e-02,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          6.00470958e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.55259027e-01,   8.88932496e-02,   1.92307692e-02,\n",
       "          0.00000000e+00],\n",
       "       [  2.85714286e-01,   0.00000000e+00,   2.85714286e-01,\n",
       "          2.85714286e-01,   1.42857143e-01,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.42857143e-01,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.42857143e-01,   1.42857143e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.85714286e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.42857143e-01,   1.42857143e-01,\n",
       "          0.00000000e+00,   2.85714286e-01,   1.42857143e-01,\n",
       "          1.42857143e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.42857143e-01,\n",
       "          1.42857143e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.42857143e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          5.71428571e-01,   0.00000000e+00,   1.42857143e-01,\n",
       "          0.00000000e+00]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
